Our data on soviet repressions come from  \citet{zhukov_stalins_2018}\footnote{In particular, we downloaded the data from the replications file archive of the journal available  at \url{https://www.prio.org/JPR/Datasets/}} who use  the Victims of Political Terror archive \footnote{The Memorial archive can be accessed at \url{http://base.memo.ru/} (new version) or at \url{http://lists.memo.ru/} (older version)} collected by a Russian NGO Memorial. The main sources of the Memorial lists are declassified Russian Interior Ministry documents, prosecutorâ€™s offices and the Commission for the Rehabilitation of Victims of Political Repression.
 The Memorial archives include 2.3 million individual arrests by the Soviet secret police (NKVD) between  the years 1921 and 1959 with names of each person, date of arrest, the place of birth for all observations and  in many cases additional information such as ethnicity, occupation and party membership. 
 However the data are not complete and include about 70\% of estimated 3.8 million convicted for political reasons.


We created our main dataset by counting number of arrest for each ethnicity by year-quater.  A few people who were categorized as having multiple ethnicities were dropped from the dataset and not counted. 
With 17  minorities (Armenian, Belarussian, Estonian, German, Greek, Chechen, Chinese, Jewish, Kabardin, Kalmyk, Korean, Latvian, Lithuanian, Ossetian, Polish, Tatar and Ukrainian) and 148 time periods (from 1921 to 1958) this gives us 2652 observations in total. Total number of arrests for each ethnicity is provided in the table \ref{tab:} and the plot of arrest by ethnicity and year (after applying the transformation $\log\left(1 + y_{it}\right)$) is shown in figure \ref{fig:universe}, both in the appendix. 

In addition to data on repressions, we also obtained some information on a few characteristics of the 17 ethnic groups in the USSR. 
Specifically, we acquired total population of the ethnic groups and their urbanization rate from 1926 Soviet Census from the Demoscope website.\footnote{It is available online at \url{http://www.demoscope.ru/weekly/ssp/ussr_nac_26.php}} For each ethnic group, we also calculated the cladisitc similarity of its language to Russian based from Glottolog language trees \citep{hammarstrom_glottolog_2018}.
Cladistic measure of linguistic similarity counts the number of shared branching points between the two nodes on a language tree and it has been used by \citet{fearon_ethnic_2003} and \citet{dickens_ethnolinguistic_2018} among others. 
%For example, Ukrainian and Russian have the cladisitc similarity of 4 since they are both 
The full data are provided in the table \ref{tab:} in the appendix. 
\subsection{Inferring Ethnicity from Names}
Let  $\boldsymbol{x} = \left(x_1, x_2, x_3\right)$ be features used for predicting ethnicity, that is a person's first name, last name and number of names. Using Bayes theorem, we can express the probability that particular observation  belongs to ethnic group $E_k$ given its features as
\begin{equation*}
p(E_k \mid \mathbf{x}) = \frac{p(E_k) \ p(\mathbf{x} \mid E_k)}{p(\mathbf{x})}
\end{equation*}
in other words, the posterior probability is proportional to the product of prior probability and likelihood. 
Assuming conditional independence of features allows us to substitute $p(\mathbf{x} \mid E_k)$ such that we get

\begin{equation*}
p(E_k \mid \mathbf{x}) = \frac{p(E_k) \  \prod_{i=1}^3 p(x_i \mid E_k)\,}{p(\mathbf{x})}
\end{equation*}
All the terms in this equation can be estimated from the data: the prior probability $p(E_k)$ as a proportion of $E_k$ in the data, $p(x_i \mid E_k)$ as a proportion of people with name $x_i$ in the ethnic group $E_k$ and $p(\mathbf{x})$ simply calculated such that the sum of $p(E_k \mid \mathbf{x})$ for all $k$ is one.

Finally, we also apply Laplace smoothing. 

The Naive Bayes classifier then chooses the ethnicity with the highest posterior probability as its prediction
\begin{equation*}
    \hat{y} = \underset{k \in \{1, \dots, K\}}{\operatorname{argmax}} \ p(E_k) \displaystyle\prod_{i=1}^{3} p(x_i \mid E_k)
\end{equation*}

% Laplacian smoothin

It is important to note that the conditional independence assumption often does not hold in the data. The estimated posterior probabilities have to be taken with a grain of salt. %have are thus not always reliable. 
However, our main goal is the best out-of-sample accuracy of the model's predictions. In this respect, Naive Bayes classifier have been shown to perform  well in many applications, despite its often violated assumptions \citep{domingos_optimality_1997}.


To reliably asses the out-of-sample performance of our model, we used 10-fold cross-validation on the training dataset. That is, the data are first randomly split into 10 groups, Then the model is fit to the data from to the data ..  
Using this method, we get the overall 75.4\% accuracy. Nevertheless, it varies
significantly by ethnicity. The specificity and sensitivity by ethnic group are provided in the table \ref{tab:sens_spec}. Some ethnic groups with distinctive names such as Chinese, Korean and German are classified fairly well with sensitivity higher than 75\%. 

Thus, there are biases in our predictions. However, we can try to adjust for them. Let $P_{it}$ be the number of people with predicted ethnicity $i$ arrested at time $t$, $R_{it}$ be actual the number of people with ethnicity $i$ arrested at time $t$, $\alpha_i$ and $\beta_i$  be sensitivity and specificity of our classifier for ethnic group $i$ and $N_t$ be the total number of arrests at time $t$. Then the predicted arrests of a given ethnicity are sum of true positives and false positives, that is
\begin{equation*}
    P_{it} = \alpha_i R_{it} + \left( N_t - R_{it} \right) \cdot \left(1 - \beta_i \right)  
\end{equation*}
We are interested in $R_{it}$ but we only directly observe $P_{it}$ and $N_t$. However using simple algebra, $R_{it}$ can be expressed as
\begin{equation*}
 R_{it} = \frac{P_{it} - N_t  \left(1 - \beta_i \right)}{\alpha_i + \beta_i - 1}
\end{equation*}
The parameters $\alpha_i$ and $\beta_i$ are not known to us but we can use their estimates from the cross-validation on the training data. This assumes that the these parameters do not differ significantly for the training and test data. But this might not be the case. 
Suppose, for example, that Armenians are often misclassified as Chechens and that the number of Armenians in the data with missing ethnicity  is disproportionately higher than in the data with information on ethnicity. 
Then the cross-validated specificity for Chechens in the training set will underestimate the specificity in the test set because it does not take into account higher proportion of Armenians. 
%If, for example, the proportions of the arrests of some ethnic group are substantially different between the test and training set and if there is constant then 
We can im
\begin{equation*}
P_{it}  = \sum_{j = 1}^{18} b_{ij} R_{jt} \qquad i = 1, \dots, 18
\end{equation*}

First we ap
\begin{equation*}
 \mathbf{P}_t = \mathbf{B}_t \cdot \mathbf{R}_t 
\end{equation*}
Again, we can easily calculate th
\begin{equation*}
\mathbf{R}_t  = \mathbf{B}_t^{-1} \cdot  \mathbf{P}_t
\end{equation*}
%\begin{equation*}
%\begin{array}{rcl} P_{1t} & = & b_{11} R_{1} \\ 
%f(x,y,z) & = & x + y + z 
%\end{array}
%\end{equation*}



We get bigger picture by examining the
confusion matrix provided in the table \ref{tab:conf_matrix_count} in the appendix. The confusion matrix is defined as 
$$A = \left(a_{ij}\right)_{i = 1, \dots, 18,\:j = 1, \dots, 18}$$
where $a_{ij}$ is number of people with ethnicity $j$ that were classified as belonging to ethnic group $i$. We can adjust the matrix as
$$B = \left(\frac{a_{ij}}{\sum_j a_{ij}} \right)_{i = 1, \dots, 18,\:j = 1, \dots, 18}$$

